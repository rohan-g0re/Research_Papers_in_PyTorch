{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2bvtE9YxUkRV",
        "zXICKwmxgqZH",
        "cEKUpKq1Ol5X",
        "rP4DX9yuWRom"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 1: MNIST Handwritten Digit Dataset"
      ],
      "metadata": {
        "id": "hdYCqFTDHt5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BSuZn6JI_2tU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "06wy1qhSJyeD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## basic transformations which are mandotory --> i.e converting to tensor and normalization\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "# creating dataset objects - later we will also have dataloader objects\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root = '/data',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transform\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root = '/data',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transform\n",
        ")\n",
        "\n",
        "print (len(train_dataset))\n",
        "print (len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-C9awMNLBjl",
        "outputId": "c71af8f9-5327-47d8-9d0c-224da1bdee1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the dataset now contains images which can be accessed using train_dataset[x]\n",
        "# each image also has a true label whih is the actual class of that label\n",
        "# currently we are accessing the 69th image --> which turns out to be a zero\n",
        "\n",
        "sample_image, sample_label = train_dataset[69]\n",
        "\n",
        "print (sample_image.shape)\n",
        "print (sample_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obujyUJMOZGW",
        "outputId": "0f1ce530-47dc-4d46-bada-ee1d0c0748c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets also do it for test dataset\n",
        "# funny enough we have zero as the 69th image in both the datasets\n",
        "\n",
        "sample_image, sample_label = test_dataset[69]\n",
        "\n",
        "print (sample_image.shape)\n",
        "print (sample_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUhhcbWrOyQT",
        "outputId": "4f47d0e3-9939-41dc-a9ca-e6485d886c82"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 2: How to Define and Train the Discriminator Model\n"
      ],
      "metadata": {
        "id": "ScgDjlHiUe4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2.1 Discriminator architecture\n",
        "\n",
        "- Build and Inititalize network - with forward pass capabilities\n",
        "- also initialize other things like optimizer and loss"
      ],
      "metadata": {
        "id": "2bvtE9YxUkRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__ (self):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.first_conv_block = self._make_first_conv_block()\n",
        "    self.second_conv_block = self._make_second_conv_block()\n",
        "    self.final_classification_block = self._make_final_classification_block()\n",
        "\n",
        "\n",
        "  def _make_first_conv_block(self):\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    layers.append(\n",
        "        nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = 64,\n",
        "            kernel_size = 3,\n",
        "            stride = 2,\n",
        "            padding = 1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    layers.append(\n",
        "        nn.LeakyReLU(\n",
        "            negative_slope = 0.2,\n",
        "            inplace = True\n",
        "        )\n",
        "    )\n",
        "\n",
        "    layers.append(\n",
        "        nn.Dropout(\n",
        "            p = 0.4\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def _make_second_conv_block(self):\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    layers.append(\n",
        "        nn.Conv2d(\n",
        "            in_channels = 64,\n",
        "            out_channels = 64,\n",
        "            kernel_size = 3,\n",
        "            stride = 2,\n",
        "            padding = 1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    layers.append(\n",
        "        nn.LeakyReLU(\n",
        "            negative_slope = 0.2,\n",
        "            inplace = True\n",
        "        )\n",
        "    )\n",
        "\n",
        "    layers.append(\n",
        "        nn.Dropout(\n",
        "            p = 0.4\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def _make_final_classification_block (self):\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    layers.append(nn.Flatten())\n",
        "\n",
        "    layers.append(\n",
        "        nn.Linear(\n",
        "            in_features = 7*7*64,\n",
        "            out_features = 1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    layers.append(nn.Sigmoid())\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "  def forward (self, x):\n",
        "\n",
        "    x = self.first_conv_block(x)\n",
        "    x = self.second_conv_block(x)\n",
        "    x = self.final_classification_block(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "Ic-AQqN1UtUS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_discriminator():\n",
        "\n",
        "  discriminator = Discriminator()\n",
        "\n",
        "\n",
        "  # in article they have decided to use adam sgd and bce loss\n",
        "\n",
        "\n",
        "  optimizer = optim.Adam(\n",
        "      discriminator.parameters(),\n",
        "      lr = 0.0002,\n",
        "      betas = (0.5, 0.999)\n",
        "  )\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "\n",
        "  return discriminator, optimizer, criterion\n",
        "\n",
        "\n",
        "\n",
        "# discriminator, optimizer, criterion = create_discriminator()"
      ],
      "metadata": {
        "id": "AQUHJT9LfNWt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total_params = sum(p.numel() for p in discriminator.parameters())\n",
        "# trainable_params = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n",
        "# print(f\"\\nTotal Parameters: {total_params:,}\")\n",
        "# print(f\"Trainable Parameters: {trainable_params:,}\")"
      ],
      "metadata": {
        "id": "rXGjwSZ7gZ4D"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2.2 Setup Data Sources for Discriminator"
      ],
      "metadata": {
        "id": "zXICKwmxgqZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase 2.2.1 Function that will provide REAL IMAGES\n",
        "\n",
        "Approach:\n",
        "1. Load the data\n",
        "2. Sample random images from it - along with their labels"
      ],
      "metadata": {
        "id": "cEKUpKq1Ol5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(train_dataset, batch_size = len(train_dataset), shuffle = True)\n",
        "  # we loaded the complete dataset and NOT A BATCH of images\n",
        "\n",
        "images, _ = next(iter(dataloader))\n"
      ],
      "metadata": {
        "id": "iZHhXEnPfGld"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_real_samples(n_samples = 100):\n",
        "\n",
        "  # we already have the dataset loaded in train_dataset from the phase 1 cells\n",
        "  # therefore we plan to use it\n",
        "\n",
        "  # dataloader = DataLoader(train_dataset, batch_size = len(train_dataset), shuffle = True)\n",
        "  # # we loaded the complete dataset and NOT A BATCH of images\n",
        "\n",
        "  # images, _ = next(iter(dataloader))\n",
        "\n",
        "  \"\"\"\n",
        "  we dont want the labels of the data points because we are not interested in the class of labels as\n",
        "  1,2,3,4... --> we are just interest in classifying wherther this is real or fake\n",
        "\n",
        "  Therefore, we will be later setting the labels as \"1\" for all the images\n",
        "  which would basically means that:\n",
        "\n",
        "  \"The randomly sampled n_samples images - belong to the class 1 - which is REAL IMAGES\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "  # ----->>>>> we have the dataset already - now lets generate randomized n_samples -----\n",
        "\n",
        "\n",
        "  indices = torch.randint(0, images.shape[0], (n_samples, ))\n",
        "\n",
        "  train_images = images[indices]\n",
        "\n",
        "  # we are just having labels as 1 bcoz they are from real image dataset\n",
        "  train_labels = torch.ones(n_samples, 1)\n",
        "\n",
        "\n",
        "\n",
        "  return train_images, train_labels\n",
        "\n",
        "\n",
        "train_real_images, train_real_labels = generate_real_samples()\n",
        "print(f\"Real images shape: {train_real_images.shape}\")\n",
        "print(f\"Real images range: [{train_real_images.min():.3f}, {train_real_images.max():.3f}]\")\n",
        "print(f\"Real images shape: {train_real_labels.shape}\")\n",
        "print(f\"Real images range: [{train_real_labels.min():.3f}, {train_real_labels.max():.3f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgsg7LU3gk-g",
        "outputId": "6db2aa49-acf1-41bd-c1c3-39d7971f0b58"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real images shape: torch.Size([100, 1, 28, 28])\n",
            "Real images range: [-1.000, 1.000]\n",
            "Real images shape: torch.Size([100, 1])\n",
            "Real images range: [1.000, 1.000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase 2.2.2 Function that will provide FAKE IMAGES\n",
        "\n",
        "**We don’t have a generator model yet, so instead, we can generate images comprised of random pixel values, specifically random pixel values in the range [0,1] like our scaled real images.**\n",
        "\n",
        "Approach:\n",
        "1. Random pixels for image"
      ],
      "metadata": {
        "id": "rP4DX9yuWRom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_random_samples(n_samples = 100):\n",
        "\n",
        "\n",
        "  train_images = torch.rand(n_samples, 1, 28, 28)\n",
        "\n",
        "\n",
        "  train_labels = torch.zeros(n_samples, 1)\n",
        "\n",
        "  return train_images, train_labels\n",
        "\n",
        "\n",
        "\n",
        "train_fake_images, train_fake_labels = generate_fake_random_samples()\n",
        "print(f\"Real images shape: {train_fake_images.shape}\")\n",
        "print(f\"Real images range: [{train_fake_images.min():.3f}, {train_fake_images.max():.3f}]\")\n",
        "print(f\"Real images shape: {train_fake_labels.shape}\")\n",
        "print(f\"Real images range: [{train_fake_labels.min():.3f}, {train_fake_labels.max():.3f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxsEavUvTZO5",
        "outputId": "e7e236e0-77e0-4c55-c6e4-b7c18e967ac7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real images shape: torch.Size([100, 1, 28, 28])\n",
            "Real images range: [0.000, 1.000]\n",
            "Real images shape: torch.Size([100, 1])\n",
            "Real images range: [0.000, 0.000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2.3 Training Discriminator\n"
      ],
      "metadata": {
        "id": "2umyPigga3Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_discriminator(discriminator, optimizer, criterion, n_iter=100, n_batch=256):\n",
        "\n",
        "    half_batch = n_batch // 2  # Split batch: half real, half fake\n",
        "\n",
        "    # Track training progress\n",
        "    real_accuracies = []\n",
        "    fake_accuracies = []\n",
        "\n",
        "    discriminator.train()  # Set to training mode (enables dropout)\n",
        "\n",
        "    for i in range(n_iter):\n",
        "\n",
        "        # ============================================\n",
        "        # PHASE 1: TRAIN ON REAL IMAGES\n",
        "        # ============================================\n",
        "\n",
        "        # Generate batch of real samples\n",
        "        X_real, y_real = generate_real_samples(half_batch)\n",
        "\n",
        "        # Forward pass through discriminator\n",
        "        pred_real = discriminator(X_real)  # Shape: [half_batch, 1]\n",
        "\n",
        "        # Calculate loss: how wrong are predictions on real images?\n",
        "        # MATHEMATICAL INSIGHT: BCE loss = -[y*log(p) + (1-y)*log(1-p)]\n",
        "        # For real images (y=1): loss = -log(p), minimized when p→1\n",
        "        loss_real = criterion(pred_real, y_real)\n",
        "\n",
        "        # Calculate accuracy before updating\n",
        "        # TECHNICAL NOTE: Convert probabilities to binary predictions\n",
        "        pred_real_binary = (pred_real > 0.5).float()\n",
        "        real_acc = (pred_real_binary == y_real).float().mean().item()\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        loss_real.backward()   # Compute gradients\n",
        "        optimizer.step()       # Update weights\n",
        "\n",
        "\n",
        "\n",
        "        # ============================================\n",
        "        # PHASE 2: TRAIN ON FAKE IMAGES\n",
        "        # ============================================\n",
        "\n",
        "\n",
        "\n",
        "        # Generate batch of fake samples\n",
        "        X_fake, y_fake = generate_fake_random_samples(half_batch)\n",
        "\n",
        "        # Forward pass\n",
        "        pred_fake = discriminator(X_fake)\n",
        "\n",
        "        # Calculate loss on fake images\n",
        "        # For fake images (y=0): loss = -log(1-p), minimized when p→0\n",
        "        loss_fake = criterion(pred_fake, y_fake)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        pred_fake_binary = (pred_fake > 0.5).float()\n",
        "        fake_acc = (pred_fake_binary == y_fake).float().mean().item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss_fake.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # ============================================\n",
        "        # MONITORING AND LOGGING\n",
        "        # ============================================\n",
        "\n",
        "        real_accuracies.append(real_acc)\n",
        "        fake_accuracies.append(fake_acc)\n",
        "\n",
        "        # Print progress every 10 iterations\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print(f'Iteration {i+1:>3d}: Real={real_acc*100:5.1f}% Fake={fake_acc*100:5.1f}%')\n",
        "\n",
        "    return real_accuracies, fake_accuracies\n"
      ],
      "metadata": {
        "id": "vdwCBLM-ci36"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the training\n",
        "print(\"Training Discriminator...\")\n",
        "\n",
        "discriminator, optimizer, criterion = create_discriminator()\n",
        "\n",
        "real_accs, fake_accs = train_discriminator(\n",
        "    discriminator=discriminator,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    n_iter=100,\n",
        "    n_batch=256\n",
        ")\n",
        "\n",
        "print(f\"\\nFinal Performance:\")\n",
        "print(f\"Real Image Accuracy: {real_accs[-1]*100:.1f}%\")\n",
        "print(f\"Fake Image Accuracy: {fake_accs[-1]*100:.1f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4IerduxcnOe",
        "outputId": "24192a83-854f-4242-ccc7-8057886ffe3d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Discriminator...\n",
            "Iteration  10: Real=100.0% Fake=100.0%\n",
            "Iteration  20: Real=100.0% Fake=100.0%\n",
            "Iteration  30: Real=100.0% Fake=100.0%\n",
            "Iteration  40: Real=100.0% Fake=100.0%\n",
            "Iteration  50: Real=100.0% Fake=100.0%\n",
            "Iteration  60: Real=100.0% Fake=100.0%\n",
            "Iteration  70: Real=100.0% Fake=100.0%\n",
            "Iteration  80: Real=100.0% Fake=100.0%\n",
            "Iteration  90: Real=100.0% Fake=100.0%\n",
            "Iteration 100: Real=100.0% Fake=100.0%\n",
            "\n",
            "Final Performance:\n",
            "Real Image Accuracy: 100.0%\n",
            "Fake Image Accuracy: 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dM1crY8HduNp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PHASE 3: How to Define and Use the Generator Model"
      ],
      "metadata": {
        "id": "qwYYUYbviTO-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_FixU8AGjFPn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}